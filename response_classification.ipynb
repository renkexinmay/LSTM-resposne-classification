{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Response classification",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renkexinmay/LSTM-resposne-classification/blob/master/response_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qaWrMZB6qljY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "To better classify the responses, it would be helpful if the model can take into account the quantitative relationship between responses and questions.\n",
        "Thus, the questions and reponses should be seperate in input set.\n",
        "\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "LSTM sentiment analysis (Keras): https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e\n",
        "\n",
        "RNN sentiment analysis (PyTorch): https://github.com/bentrevett/pytorch-sentiment-analysis\n",
        "\n",
        "**Unsupervised learning:**\n",
        "..."
      ]
    },
    {
      "metadata": {
        "id": "XHkb6EFftgaJ",
        "colab_type": "code",
        "outputId": "f18569ff-7e9f-4727-b52f-ec8d6ac173b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 1: LSTM in Keras (ref:  https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e)\n",
        "\n",
        "## load data\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoRL3KqIyfeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## vectorize the words and sentences + pre-trained vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZyuTxIX8xd1T",
        "colab_type": "code",
        "outputId": "614afb7b-a1d8-494b-c84b-205aaba50d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "vocabulary_size = 50000 # Top most frequent words to consider. Any less frequent word will appear as oov_char value in the sequence data.\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "\n",
        "print('Loaded data with {} training samples and {} test samples'.format(len(X_train), len(X_test)))\n",
        "print('Max sentence length: {}'.format(len(max(X_train, key = len))))\n",
        "print('Min sentence length: {}'.format(len(min(X_train, key = len))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "Loaded data with 25000 training samples and 25000 test samples\n",
            "Max sentence length: 2494\n",
            "Min sentence length: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZtplh3TylhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Pad sequences: make the input data have save length (padding short ones with 0)\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = max_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YH-akXy_2fp1",
        "colab_type": "code",
        "outputId": "9515980c-3d10-42b3-b9a8-f83037b403a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "## model\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "embedding_size = 32\n",
        "model = Sequential() # a linear stack of layers\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length = max_words)) # add the first layer, embedding each word by a 32-dim vector, instead of 5000-dim one-hot vector\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation = 'softmax')) #softmax for multi category classification; sigmoid for binary classification\n",
        "\n",
        "## question: how to determine #layers of LSTM; function of Dense layer; how to get #param of LSTM & Dense\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           1600000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,653,301\n",
            "Trainable params: 1,653,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fRxZvKnPbiPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', # categorical_crossentropy for multi category classification; binary_crossentropy for binary classification\n",
        "             optimizer = 'adam',\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "## question: binary_crossentropy? categorical_crossentropy?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEPD7P18lmiK",
        "colab_type": "code",
        "outputId": "d72860b7-ea98-4ad3-ecf3-970026eabc2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train2, y_train2, validation_data = (X_valid, y_valid),\n",
        "batch_size = batch_size, epochs = num_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24936 samples, validate on 64 samples\n",
            "Epoch 1/5\n",
            "24936/24936 [==============================] - 256s 10ms/step - loss: 7.9667 - acc: 0.5003 - val_loss: 9.7149 - val_acc: 0.3906\n",
            "Epoch 2/5\n",
            "24936/24936 [==============================] - 254s 10ms/step - loss: 7.9667 - acc: 0.5003 - val_loss: 9.7149 - val_acc: 0.3906\n",
            "Epoch 3/5\n",
            "24936/24936 [==============================] - 253s 10ms/step - loss: 7.9667 - acc: 0.5003 - val_loss: 9.7149 - val_acc: 0.3906\n",
            "Epoch 4/5\n",
            "24936/24936 [==============================] - 253s 10ms/step - loss: 7.9667 - acc: 0.5003 - val_loss: 9.7149 - val_acc: 0.3906\n",
            "Epoch 5/5\n",
            "24936/24936 [==============================] - 255s 10ms/step - loss: 7.9667 - acc: 0.5003 - val_loss: 9.7149 - val_acc: 0.3906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bd79a940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "iiMyMYY5nhkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print('Test accurary', scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5CNFbo9nWnI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "The accuracy is only 0.5. Let's try something else\n",
        "\n",
        "RNN-based classification using PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "D0TrkZzqqyG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Iy7bSAgq1G2",
        "colab_type": "code",
        "outputId": "f873fe20-910e-478e-907c-c65c1a14eca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/pytorch/text/archive/master.zip\n",
        "from torchtext import data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/pytorch/text/archive/master.zip\n",
            "  Downloading https://github.com/pytorch/text/archive/master.zip\n",
            "\u001b[K     \\ 880kB 95.0MB/s\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (2.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.11.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2.6)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-8rm4kf_z/wheels/5a/86/3d/30ae7dfdfeb1748bb11b3da173fb9634141fbb39e9e9847317\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JwwcR0EDroMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wH9Zu4xsrunL",
        "colab_type": "code",
        "outputId": "e742f428-887e-4526-b3a6-3004e0a04c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:06<00:00, 13.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NsQUc3hksK42",
        "colab_type": "code",
        "outputId": "300e010b-5672-485b-c4ca-b7736a16343a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of test examples: {len(test_data)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of test examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eVDJEJcUyHlZ",
        "colab_type": "code",
        "outputId": "7e368e64-8be9-42fd-f2ea-8aa2786a7ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(vars(test_data.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Rachael', 'Ray', 'appeals', 'to', 'viewers', 'of', 'all', 'ages', 'and', 'backgrounds', ',', 'beginner', 'cooks', 'or', '\"', 'seasoned', '\"', 'veterans', '.', 'You', \"'ll\", 'be', 'dazzled', 'with', 'a', 'variegated', 'presentation', 'of', 'delectable', 'yet', 'time', '-', 'efficient', 'dishes', ',', 'jazzed', 'up', 'with', 'her', 'unique', 'brand', 'of', 'spunk', 'and', 'candor', '.', 'Most', 'importantly', ',', 'this', 'hip', 'chic', 'keeps', 'her', 'audience', 'drawn', 'in', 'by', 'stimulating', 'all', 'five', 'senses', '.', 'Let', 'me', 'explain', '.', 'Her', 'program', 'provides', 'enlightenment', 'to', 'your', 'visual', 'sense', ',', 'auditory', 'sense', ',', 'and', 'sense', 'of', 'feeling', 'through', 'a', 'rich', ',', 'luminous', 'ambient', 'backdrop', ',', 'light', '-', 'hearted', ',', 'casual', ',', 'yet', 'engaging', 'topics', ',', 'eye', '-', 'pleasing', ',', 'appetite', 'wrenching', 'meals', ',', 'and', 'her', 'hearty', 'smile', 'and', 'laugh', ',', 'which', 'will', 'simmer', 'down', 'anyone', \"'s\", 'nerves.(Sense', 'of', 'smell', 'and', 'taste', 'are', 'rewarded', 'when', 'you', 'test', 'out', 'the', 'recipes', 'in', 'your', 'own', 'kitchen', 'and', 'among', 'your', 'own', 'family', 'and', 'friends', ')', '.', 'Check', 'out', 'her', 'show', 'guys', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tCM-QBODzmiC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OV2D28P94Uox",
        "colab_type": "code",
        "outputId": "e0b465de-7d4d-4b63-b47e-e8964812f155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "svdJXbu_8Nfl",
        "colab_type": "code",
        "outputId": "206e8511-b2a7-4a64-dc08-fd9513a3fdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size = 25000, vectors = \"glove.6B.100d\")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:09, 6.67MB/s]                           \n",
            "100%|█████████▉| 398651/400000 [00:16<00:00, 24940.40it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RaZYb-5P71ZN",
        "colab_type": "code",
        "outputId": "0d21ead9-074f-4995-fa66-524c978bc899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\") # <pad> for blanks in short sentence; <unk> for less frequent words\n",
        "print(f\"Unique tokens in LABELS vocabulary: {len(LABEL.vocab)}\")\n",
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABELS vocabulary: 2\n",
            "[('the', 202312), (',', 192493), ('.', 164175), ('and', 108868), ('a', 108719), ('of', 100745), ('to', 93419), ('is', 75919), ('in', 61168), ('I', 53720), ('it', 53417), ('that', 48849), ('\"', 44694), (\"'s\", 43428), ('this', 42014), ('-', 36969), ('/><br', 35724), ('was', 34871), ('as', 30245), ('with', 29966)]\n",
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
            "defaultdict(<function _default_unk_index at 0x7f09318cff28>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JQp2lWOk80Gb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSa5mAUr-yUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "    super(RNN, self).__init__()\n",
        "    # input dim = voc size = one-hot vec dim\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout)\n",
        "    self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    #x = [sent len, batch size]\n",
        "    embedded = self.dropout(self.embedding(x))\n",
        "    \n",
        "    #embedded = [sen len, batch size, emb dim]\n",
        "    \n",
        "    output, (hidden, cell) = self.rnn(embedded)\n",
        "    \n",
        "    #output = [sen len, batch size, hid dim]\n",
        "    #hidden, cell = [num layers * num directions, batch size, hid dim]\n",
        "    \n",
        "    # concat the final forward (hidden[-2,:,:] and backward (hidden[-1, :,:])) hidden layers\n",
        "    # and apply dropout\n",
        "    \n",
        "    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]),dim = 1))\n",
        "    \n",
        "    # hidden = [batch size, hid dim * num directions]\n",
        "       \n",
        "    return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWkthmJgXvyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100 # = pre-trained GloVe vectors loaded\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NjHHqwzx05p",
        "colab_type": "code",
        "outputId": "5799be18-8118-47ac-b4d0-8f9fea0a9f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A0vK9bMVyC55",
        "colab_type": "code",
        "outputId": "c54ade72-e4a9-4786-ddda-46ea537625e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.0378, -0.0032,  0.2337,  ..., -0.1429, -0.5320, -0.9142],\n",
              "        [ 0.4106, -0.6026,  0.1699,  ..., -0.7372, -0.0973, -0.1677],\n",
              "        [ 0.0501, -0.0960, -0.1318,  ...,  0.2636, -0.5630, -0.3210]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "M9OLQpt3YI0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss() #grad & loss\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "# place them on GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAdSbK5iVotX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def binary_accuracy(preds, y):\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_preds == y).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCrIGbWrZEpt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  for batch in iterator:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    \n",
        "    loss = criterion(predictions, batch.label)\n",
        "    \n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "    \n",
        "    return epoch_loss/ len(iterator), epoch_acc/ len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJGcm9ViA6Py",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      \n",
        "      acc = binary_accuracy(predictions, batch.label)\n",
        "      \n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "      \n",
        "  return epoch_loss/ len(iterator), epoch_acc/ len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uscJVCtxFKlj",
        "colab_type": "code",
        "outputId": "c371c812-151c-4ac4-a63d-53909d02e66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  \n",
        "  print(f'| Epoch: {epoch+1:02} | Train Loss:{train_loss:.3f}  | Train Accuracy: {train_acc*100:.2f}% | Val.Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.25}% |')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss:0.003  | Train Accuracy: 0.18% | Val.Loss: 0.694 | Val. Acc: 50.73711157350216893746619% |\n",
            "| Epoch: 02 | Train Loss:0.003  | Train Accuracy: 0.14% | Val.Loss: 0.693 | Val. Acc: 50.73711157350216893746619% |\n",
            "| Epoch: 03 | Train Loss:0.003  | Train Accuracy: 0.20% | Val.Loss: 0.693 | Val. Acc: 50.75476694915253972339997% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NTdfMXYcGWUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZ7e6JJfzeLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#predict function"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}